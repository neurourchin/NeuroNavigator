% The soft actor-critic (SAC) algorithm is a model-free, online, 
% off-policy, actor-critic reinforcement learning method. The SAC 
% algorithm computes an optimal policy that maximizes both the 
% long-term expected reward and the entropy of the policy. The policy 
% entropy is a measure of policy uncertainty given the state. A higher 
% entropy value promotes more exploration. Maximizing both the reward 
% and the entropy balances exploration and exploitation of the environment.